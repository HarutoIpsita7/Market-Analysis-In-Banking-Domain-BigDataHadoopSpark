{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jaya Jagannatha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"/usr/local/spark\")\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Market Aalysis in Banking Domain\").getOrCreate()\n",
    "from pyspark.sql import Row\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "=================================================================================================================\n",
    "To increase the ram size incase u get an error as:\n",
    "An error occurred while calling o194.showString. : org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 138.0\n",
    "=================================================================================================================\n",
    "config=pyspark.SparkConf().setAll(\n",
    "    [\n",
    "        (\"spark.memory.offHeap.enabled\",\"true\"),\n",
    "        (\"spark.memory.offHeap.size\",\"12gb\")\n",
    "    ]\n",
    ")\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Market Aalysis in Banking Domain\").config(conf=config).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.\tLoad data and create a Spark data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile(\"Project 1_dataset_bank-full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "removing_delemiters = rdd.map(lambda wrd: wrd.replace('\"',\"\")).map(lambda l: l.split(';'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(removing_delemiters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['age',\n",
       "  'job',\n",
       "  'marital',\n",
       "  'education',\n",
       "  'default',\n",
       "  'balance',\n",
       "  'housing',\n",
       "  'loan',\n",
       "  'contact',\n",
       "  'day',\n",
       "  'month',\n",
       "  'duration',\n",
       "  'campaign',\n",
       "  'pdays',\n",
       "  'previous',\n",
       "  'poutcome',\n",
       "  'y'],\n",
       " ['58',\n",
       "  'management',\n",
       "  'married',\n",
       "  'tertiary',\n",
       "  'no',\n",
       "  '2143',\n",
       "  'yes',\n",
       "  'no',\n",
       "  'unknown',\n",
       "  '5',\n",
       "  'may',\n",
       "  '261',\n",
       "  '1',\n",
       "  '-1',\n",
       "  '0',\n",
       "  'unknown',\n",
       "  'no'],\n",
       " ['44',\n",
       "  'technician',\n",
       "  'single',\n",
       "  'secondary',\n",
       "  'no',\n",
       "  '29',\n",
       "  'yes',\n",
       "  'no',\n",
       "  'unknown',\n",
       "  '5',\n",
       "  'may',\n",
       "  '151',\n",
       "  '1',\n",
       "  '-1',\n",
       "  '0',\n",
       "  'unknown',\n",
       "  'no']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removing_delemiters.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_headers = removing_delemiters.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'job',\n",
       " 'marital',\n",
       " 'education',\n",
       " 'default',\n",
       " 'balance',\n",
       " 'housing',\n",
       " 'loan',\n",
       " 'contact',\n",
       " 'day',\n",
       " 'month',\n",
       " 'duration',\n",
       " 'campaign',\n",
       " 'pdays',\n",
       " 'previous',\n",
       " 'poutcome',\n",
       " 'y']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = removing_delemiters.filter(lambda each: each != bank_headers).toDF(bank_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: string (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: string (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- campaign: string (nullable = true)\n",
      " |-- pdays: string (nullable = true)\n",
      " |-- previous: string (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "|age|         job|marital|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|  y|\n",
      "+---+------------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "| 58|  management|married| tertiary|     no|   2143|    yes|  no|unknown|  5|  may|     261|       1|   -1|       0| unknown| no|\n",
      "| 44|  technician| single|secondary|     no|     29|    yes|  no|unknown|  5|  may|     151|       1|   -1|       0| unknown| no|\n",
      "| 33|entrepreneur|married|secondary|     no|      2|    yes| yes|unknown|  5|  may|      76|       1|   -1|       0| unknown| no|\n",
      "| 47| blue-collar|married|  unknown|     no|   1506|    yes|  no|unknown|  5|  may|      92|       1|   -1|       0| unknown| no|\n",
      "| 33|     unknown| single|  unknown|     no|      1|     no|  no|unknown|  5|  may|     198|       1|   -1|       0| unknown| no|\n",
      "+---+------------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int, job: string, marital: string, education: string, default: string, balance: string, housing: string, loan: string, contact: string, day: string, month: string, duration: string, campaign: string, pdays: string, previous: string, poutcome: string, y: string]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.withColumn(\"age\",data.age.cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: string, job: string, marital: string, education: string, default: string, balance: double, housing: string, loan: string, contact: string, day: string, month: string, duration: string, campaign: string, pdays: string, previous: string, poutcome: string, y: string]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.withColumn(\"balance\",data.balance.cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: string, job: string, marital: string, education: string, default: string, balance: string, housing: string, loan: string, contact: string, day: string, month: string, duration: string, campaign: string, pdays: string, previous: int, poutcome: string, y: string]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.withColumn(\"day\",data.day.cast(IntegerType()))\n",
    "data.withColumn(\"duration\",data.duration.cast(IntegerType()))\n",
    "data.withColumn(\"campaign\",data.campaign.cast(IntegerType()))\n",
    "data.withColumn(\"pdays\",data.pdays.cast(IntegerType()))\n",
    "data.withColumn(\"previous\",data.previous.cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: string (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: string (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- campaign: string (nullable = true)\n",
      " |-- pdays: string (nullable = true)\n",
      " |-- previous: string (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# does not work only using these command\n",
    "# data = spark.read.load('Project 1_dataset_bank-full.csv',format=\"csv\",sep=\";\",inferSchema=True,header=True)\n",
    "# data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|age|\n",
      "+---+\n",
      "| 58|\n",
      "| 44|\n",
      "| 33|\n",
      "+---+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('age').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|         job|\n",
      "+------------+\n",
      "|  management|\n",
      "|  technician|\n",
      "|entrepreneur|\n",
      "+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('job').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: string (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: string (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- campaign: string (nullable = true)\n",
      " |-- pdays: string (nullable = true)\n",
      " |-- previous: string (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "|age|       job|marital|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|  y|\n",
      "+---+----------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "| 58|management|married| tertiary|     no|   2143|    yes|  no|unknown|  5|  may|     261|       1|   -1|       0| unknown| no|\n",
      "+---+----------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col \n",
    "import pyspark.sql.types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumn(\"age\",col(\"age\").cast(IntegerType()))\n",
    "data = data.withColumn(\"balance\",col(\"balance\"). cast(DoubleType()))\n",
    "data = data.withColumn(\"balance\",col(\"balance\"). cast(IntegerType()))\n",
    "data = data.withColumn(\"day\",col(\"day\"). cast(IntegerType()))\n",
    "data = data.withColumn(\"duration\",col(\"duration\"). cast(IntegerType()))\n",
    "data = data.withColumn(\"pdays\",col(\"pdays\"). cast(IntegerType()))\n",
    "data = data.withColumn(\"campaign\",col(\"campaign\"). cast(IntegerType()))\n",
    "data = data.withColumn(\"previous\",col(\"previous\"). cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: integer (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\tGive marketing success rate (No. of people subscribed / total no. of entries)  Give marketing failure rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|  y|count|\n",
      "+---+-----+\n",
      "| no|39922|\n",
      "|yes| 5289|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupBy('y').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.createOrReplaceTempView(\"bank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+\n",
      "|subscription|  y|\n",
      "+------------+---+\n",
      "|       39922| no|\n",
      "|        5289|yes|\n",
      "+------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('Select count(*) as subscription,y from bank group by y').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+\n",
      "|No. of people subscribed - Marketing success rate|\n",
      "+-------------------------------------------------+\n",
      "|                               11.698480458295547|\n",
      "+-------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select (\\\n",
    "(select count(*) from bank where y = \"yes\")/\\\n",
    "(select count(*) from bank)*\\\n",
    "         100) as `No. of people subscribed - Marketing success rate`').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|Marketing failure rate|\n",
      "+----------------------+\n",
      "|     88.30151954170445|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select (\\\n",
    "(select count(*) from bank where y = \"no\")/\\\n",
    "(select count(*) from bank)*\\\n",
    "         100) as `Marketing failure rate`').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.\tGive the maximum, mean, and minimum age of the average targeted customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----------------+\n",
      "|minimum age|maximum age|         mean age|\n",
      "+-----------+-----------+-----------------+\n",
      "|         18|         95|40.93621021432837|\n",
      "+-----------+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select MIN(age) as `minimum age`,MAX(age) as `maximum age`,MEAN(age) as `mean age` from bank').show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# does not work\n",
    "# data.select(\"age\").summary(\"count\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.\tCheck the quality of customers by checking average balance, median balance of customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql('select (\\\n",
    "#              (select max(balance) from\\\n",
    "#                  (select top 50 percent balance from bank order by balance) as bottom_half)\\\n",
    "#             +\\\n",
    "#               (select min(balance) from\\\n",
    "#                   (select top 50 percent balance from bank order by balance desc) as top_half)\\\n",
    "#          ) / 2 as median').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(\"SELECT balance,\\\n",
    "#     PERCENTILE_CONT(0.5) \\\n",
    "#         WITHIN GROUP (ORDER BY balance)\\\n",
    "#         OVER (PARTITION BY SalesOrderID) AS MedianCont\\\n",
    "#     FROM bank\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|median balance|\n",
      "+--------------+\n",
      "|         448.0|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select percentile_approx(balance,0.5) as `median balance` FROM bank').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|      avg(balance)|\n",
      "+------------------+\n",
      "|1362.2720576850766|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(avg(\"balance\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|avg balance of customers|\n",
      "+------------------------+\n",
      "|      1362.2720576850766|\n",
      "+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('Select AVG(balance) as `avg balance of customers` from bank').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.  Check if age matters in marketing subscription for deposit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-----+\n",
      "|  y|age|count|\n",
      "+---+---+-----+\n",
      "| no| 63|   47|\n",
      "| no| 47|  975|\n",
      "|yes| 26|  134|\n",
      "|yes| 50|   72|\n",
      "|yes| 68|   21|\n",
      "| no| 32| 1864|\n",
      "| no| 94|    1|\n",
      "| no| 74|   24|\n",
      "| no| 55|  730|\n",
      "| no| 49|  893|\n",
      "|yes| 34|  198|\n",
      "|yes| 51|   77|\n",
      "| no| 79|   15|\n",
      "|yes| 25|  113|\n",
      "|yes| 83|    6|\n",
      "|yes| 43|  103|\n",
      "|yes| 76|   16|\n",
      "| no| 21|   57|\n",
      "|yes| 92|    2|\n",
      "|yes| 49|  101|\n",
      "+---+---+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupBy('y','age').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql('select count(y),y as count_ from bank where age < 27 and age <= 37 group by y').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql('select count(y),y as count_ from bank where age < 37 and age <= 47 group by y').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql('select count(y),y as count_ from bank where age < 47 and age <= 57 group by y').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql('select count(y),y as count_ from bank where age < 57 and age <= 67 group by y').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql('select count(y),y as count_ from bank where age < 67 and age <= 77 group by y').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql('select count(y),y as count_ from bank where age < 77 and age <= 87 group by y').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql('select count(y),y as count_ from bank where age < 87 and age <= 97 group by y').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-----+\n",
      "|y  |age|count|\n",
      "+---+---+-----+\n",
      "|no |95 |1    |\n",
      "|yes|95 |1    |\n",
      "|no |94 |1    |\n",
      "|yes|93 |2    |\n",
      "|yes|92 |2    |\n",
      "|yes|90 |2    |\n",
      "|no |89 |3    |\n",
      "|no |88 |2    |\n",
      "|no |87 |1    |\n",
      "|yes|87 |3    |\n",
      "|no |86 |5    |\n",
      "|yes|86 |4    |\n",
      "|no |85 |1    |\n",
      "|yes|85 |4    |\n",
      "|no |84 |4    |\n",
      "|yes|84 |5    |\n",
      "|yes|83 |6    |\n",
      "|no |83 |16   |\n",
      "|yes|82 |8    |\n",
      "|no |82 |11   |\n",
      "|yes|81 |6    |\n",
      "|no |81 |11   |\n",
      "|yes|80 |12   |\n",
      "|no |80 |19   |\n",
      "|yes|79 |10   |\n",
      "|no |79 |15   |\n",
      "|yes|78 |14   |\n",
      "|no |78 |16   |\n",
      "|no |77 |22   |\n",
      "|yes|77 |22   |\n",
      "|yes|76 |16   |\n",
      "|no |76 |16   |\n",
      "|no |75 |24   |\n",
      "|yes|75 |15   |\n",
      "|yes|74 |13   |\n",
      "|no |74 |24   |\n",
      "|yes|73 |24   |\n",
      "|no |73 |20   |\n",
      "|no |72 |28   |\n",
      "|yes|72 |24   |\n",
      "|yes|71 |25   |\n",
      "|no |71 |29   |\n",
      "|no |70 |50   |\n",
      "|yes|70 |17   |\n",
      "|no |69 |27   |\n",
      "|yes|69 |17   |\n",
      "|no |68 |15   |\n",
      "|yes|68 |21   |\n",
      "|yes|67 |23   |\n",
      "|no |67 |31   |\n",
      "|no |66 |39   |\n",
      "|yes|66 |24   |\n",
      "|no |65 |38   |\n",
      "|yes|65 |21   |\n",
      "|no |64 |39   |\n",
      "|yes|64 |35   |\n",
      "|yes|63 |30   |\n",
      "|no |63 |47   |\n",
      "|no |62 |41   |\n",
      "|yes|62 |39   |\n",
      "|no |61 |90   |\n",
      "|yes|61 |57   |\n",
      "|yes|60 |98   |\n",
      "|no |60 |498  |\n",
      "|no |59 |682  |\n",
      "|yes|59 |88   |\n",
      "|no |58 |668  |\n",
      "|yes|58 |72   |\n",
      "|no |57 |750  |\n",
      "|yes|57 |78   |\n",
      "|no |56 |710  |\n",
      "|yes|56 |68   |\n",
      "|no |55 |730  |\n",
      "|yes|55 |76   |\n",
      "|yes|54 |84   |\n",
      "|no |54 |727  |\n",
      "|no |53 |806  |\n",
      "|yes|53 |85   |\n",
      "|no |52 |826  |\n",
      "|yes|52 |85   |\n",
      "|no |51 |859  |\n",
      "|yes|51 |77   |\n",
      "|yes|50 |72   |\n",
      "|no |50 |867  |\n",
      "|no |49 |893  |\n",
      "|yes|49 |101  |\n",
      "|no |48 |915  |\n",
      "|yes|48 |82   |\n",
      "|yes|47 |113  |\n",
      "|no |47 |975  |\n",
      "|yes|46 |118  |\n",
      "|no |46 |1057 |\n",
      "|yes|45 |106  |\n",
      "|no |45 |1110 |\n",
      "|no |44 |1043 |\n",
      "|yes|44 |93   |\n",
      "|no |43 |1058 |\n",
      "|yes|43 |103  |\n",
      "|yes|42 |111  |\n",
      "|no |42 |1131 |\n",
      "|yes|41 |120  |\n",
      "|no |41 |1171 |\n",
      "|no |40 |1239 |\n",
      "|yes|40 |116  |\n",
      "|no |39 |1344 |\n",
      "|yes|39 |143  |\n",
      "|yes|38 |144  |\n",
      "|no |38 |1322 |\n",
      "|yes|37 |170  |\n",
      "|no |37 |1526 |\n",
      "|no |36 |1611 |\n",
      "|yes|36 |195  |\n",
      "|no |35 |1685 |\n",
      "|yes|35 |209  |\n",
      "|no |34 |1732 |\n",
      "|yes|34 |198  |\n",
      "|yes|33 |210  |\n",
      "|no |33 |1762 |\n",
      "|no |32 |1864 |\n",
      "|yes|32 |221  |\n",
      "|no |31 |1790 |\n",
      "|yes|31 |206  |\n",
      "|no |30 |1540 |\n",
      "|yes|30 |217  |\n",
      "|yes|29 |171  |\n",
      "|no |29 |1014 |\n",
      "|yes|28 |162  |\n",
      "|no |28 |876  |\n",
      "|yes|27 |141  |\n",
      "|no |27 |768  |\n",
      "|yes|26 |134  |\n",
      "|no |26 |671  |\n",
      "|yes|25 |113  |\n",
      "|no |25 |414  |\n",
      "|yes|24 |68   |\n",
      "|no |24 |234  |\n",
      "|no |23 |158  |\n",
      "|yes|23 |44   |\n",
      "|no |22 |89   |\n",
      "|yes|22 |40   |\n",
      "|yes|21 |22   |\n",
      "|no |21 |57   |\n",
      "|no |20 |35   |\n",
      "|yes|20 |15   |\n",
      "|yes|19 |11   |\n",
      "|no |19 |24   |\n",
      "|yes|18 |7    |\n",
      "|no |18 |5    |\n",
      "+---+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupBy(\"y\",\"age\").count().sort(desc('age')).show(data.count(),False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "|age|number|\n",
      "+---+------+\n",
      "|95 |1     |\n",
      "|93 |2     |\n",
      "|92 |2     |\n",
      "|90 |2     |\n",
      "|87 |3     |\n",
      "|86 |4     |\n",
      "|85 |4     |\n",
      "|84 |5     |\n",
      "|83 |6     |\n",
      "|82 |8     |\n",
      "|81 |6     |\n",
      "|80 |12    |\n",
      "|79 |10    |\n",
      "|78 |14    |\n",
      "|77 |22    |\n",
      "|76 |16    |\n",
      "|75 |15    |\n",
      "|74 |13    |\n",
      "|73 |24    |\n",
      "|72 |24    |\n",
      "|71 |25    |\n",
      "|70 |17    |\n",
      "|69 |17    |\n",
      "|68 |21    |\n",
      "|67 |23    |\n",
      "|66 |24    |\n",
      "|65 |21    |\n",
      "|64 |35    |\n",
      "|63 |30    |\n",
      "|62 |39    |\n",
      "|61 |57    |\n",
      "|60 |98    |\n",
      "|59 |88    |\n",
      "|58 |72    |\n",
      "|57 |78    |\n",
      "|56 |68    |\n",
      "|55 |76    |\n",
      "|54 |84    |\n",
      "|53 |85    |\n",
      "|52 |85    |\n",
      "|51 |77    |\n",
      "|50 |72    |\n",
      "|49 |101   |\n",
      "|48 |82    |\n",
      "|47 |113   |\n",
      "|46 |118   |\n",
      "|45 |106   |\n",
      "|44 |93    |\n",
      "|43 |103   |\n",
      "|42 |111   |\n",
      "|41 |120   |\n",
      "|40 |116   |\n",
      "|39 |143   |\n",
      "|38 |144   |\n",
      "|37 |170   |\n",
      "|36 |195   |\n",
      "|35 |209   |\n",
      "|34 |198   |\n",
      "|33 |210   |\n",
      "|32 |221   |\n",
      "|31 |206   |\n",
      "|30 |217   |\n",
      "|29 |171   |\n",
      "|28 |162   |\n",
      "|27 |141   |\n",
      "|26 |134   |\n",
      "|25 |113   |\n",
      "|24 |68    |\n",
      "|23 |44    |\n",
      "|22 |40    |\n",
      "|21 |22    |\n",
      "|20 |15    |\n",
      "|19 |11    |\n",
      "|18 |7     |\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT age, count(*) as number from bank\\\n",
    "        where y = 'yes' group by age order by age desc\").show(data.count(),False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostly as u can see that as the age group people 25 - 50 \n",
    "\n",
    "more number of pople have gone for subscription\n",
    "\n",
    "So related"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Check if marital status mattered for a subscription to deposit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|marital |number|\n",
      "+--------+------+\n",
      "|married |2755  |\n",
      "|single  |1912  |\n",
      "|divorced|622   |\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT marital, count(*) as number from bank\\\n",
    "        where y = 'yes' group by marital order by number desc\").show(data.count(),False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostly as u can see that in married people\n",
    "\n",
    "more number of pople have gone for subscription\n",
    "\n",
    "So related"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.\tCheck if age and marital status together mattered for a subscription to deposit scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+\n",
      "|age|marital |number|\n",
      "+---+--------+------+\n",
      "|95 |divorced|1     |\n",
      "|93 |married |2     |\n",
      "|92 |married |2     |\n",
      "|90 |divorced|2     |\n",
      "|87 |divorced|1     |\n",
      "|87 |married |2     |\n",
      "|86 |married |2     |\n",
      "|86 |divorced|1     |\n",
      "|86 |single  |1     |\n",
      "|85 |married |3     |\n",
      "|85 |divorced|1     |\n",
      "|84 |divorced|1     |\n",
      "|84 |married |4     |\n",
      "|83 |single  |1     |\n",
      "|83 |divorced|2     |\n",
      "|83 |married |3     |\n",
      "|82 |married |5     |\n",
      "|82 |divorced|3     |\n",
      "|81 |married |4     |\n",
      "|81 |divorced|2     |\n",
      "|80 |divorced|1     |\n",
      "|80 |married |11    |\n",
      "|79 |divorced|2     |\n",
      "|79 |married |8     |\n",
      "|78 |divorced|6     |\n",
      "|78 |married |8     |\n",
      "|77 |divorced|3     |\n",
      "|77 |married |19    |\n",
      "|76 |married |10    |\n",
      "|76 |divorced|6     |\n",
      "|75 |married |12    |\n",
      "|75 |divorced|3     |\n",
      "|74 |divorced|2     |\n",
      "|74 |married |11    |\n",
      "|73 |divorced|4     |\n",
      "|73 |married |19    |\n",
      "|73 |single  |1     |\n",
      "|72 |divorced|1     |\n",
      "|72 |married |23    |\n",
      "|71 |married |17    |\n",
      "|71 |divorced|8     |\n",
      "|70 |married |12    |\n",
      "|70 |divorced|5     |\n",
      "|69 |divorced|3     |\n",
      "|69 |single  |1     |\n",
      "|69 |married |13    |\n",
      "|68 |single  |2     |\n",
      "|68 |divorced|6     |\n",
      "|68 |married |13    |\n",
      "|67 |single  |1     |\n",
      "|67 |divorced|7     |\n",
      "|67 |married |15    |\n",
      "|66 |divorced|2     |\n",
      "|66 |married |22    |\n",
      "|65 |married |19    |\n",
      "|65 |divorced|2     |\n",
      "|64 |divorced|4     |\n",
      "|64 |married |31    |\n",
      "|63 |divorced|4     |\n",
      "|63 |married |25    |\n",
      "|63 |single  |1     |\n",
      "|62 |divorced|5     |\n",
      "|62 |married |34    |\n",
      "|61 |single  |1     |\n",
      "|61 |married |47    |\n",
      "|61 |divorced|9     |\n",
      "|60 |single  |4     |\n",
      "|60 |divorced|21    |\n",
      "|60 |married |73    |\n",
      "|59 |single  |6     |\n",
      "|59 |married |66    |\n",
      "|59 |divorced|16    |\n",
      "|58 |married |54    |\n",
      "|58 |single  |1     |\n",
      "|58 |divorced|17    |\n",
      "|57 |married |58    |\n",
      "|57 |single  |5     |\n",
      "|57 |divorced|15    |\n",
      "|56 |divorced|13    |\n",
      "|56 |married |49    |\n",
      "|56 |single  |6     |\n",
      "|55 |divorced|26    |\n",
      "|55 |married |50    |\n",
      "|54 |married |52    |\n",
      "|54 |single  |8     |\n",
      "|54 |divorced|24    |\n",
      "|53 |divorced|18    |\n",
      "|53 |single  |7     |\n",
      "|53 |married |60    |\n",
      "|52 |divorced|10    |\n",
      "|52 |single  |8     |\n",
      "|52 |married |67    |\n",
      "|51 |single  |8     |\n",
      "|51 |married |59    |\n",
      "|51 |divorced|10    |\n",
      "|50 |divorced|11    |\n",
      "|50 |married |57    |\n",
      "|50 |single  |4     |\n",
      "|49 |single  |14    |\n",
      "|49 |married |71    |\n",
      "|49 |divorced|16    |\n",
      "|48 |single  |15    |\n",
      "|48 |divorced|16    |\n",
      "|48 |married |51    |\n",
      "|47 |divorced|10    |\n",
      "|47 |single  |20    |\n",
      "|47 |married |83    |\n",
      "|46 |married |80    |\n",
      "|46 |divorced|25    |\n",
      "|46 |single  |13    |\n",
      "|45 |single  |14    |\n",
      "|45 |married |68    |\n",
      "|45 |divorced|24    |\n",
      "|44 |divorced|21    |\n",
      "|44 |married |48    |\n",
      "|44 |single  |24    |\n",
      "|43 |single  |26    |\n",
      "|43 |divorced|15    |\n",
      "|43 |married |62    |\n",
      "|42 |divorced|19    |\n",
      "|42 |single  |22    |\n",
      "|42 |married |70    |\n",
      "|41 |single  |31    |\n",
      "|41 |divorced|17    |\n",
      "|41 |married |72    |\n",
      "|40 |divorced|12    |\n",
      "|40 |married |73    |\n",
      "|40 |single  |31    |\n",
      "|39 |divorced|16    |\n",
      "|39 |married |87    |\n",
      "|39 |single  |40    |\n",
      "|38 |divorced|20    |\n",
      "|38 |married |86    |\n",
      "|38 |single  |38    |\n",
      "|37 |married |98    |\n",
      "|37 |divorced|15    |\n",
      "|37 |single  |57    |\n",
      "|36 |married |100   |\n",
      "|36 |single  |71    |\n",
      "|36 |divorced|24    |\n",
      "|35 |single  |84    |\n",
      "|35 |married |101   |\n",
      "|35 |divorced|24    |\n",
      "|34 |married |118   |\n",
      "|34 |single  |69    |\n",
      "|34 |divorced|11    |\n",
      "|33 |married |97    |\n",
      "|33 |divorced|16    |\n",
      "|33 |single  |97    |\n",
      "|32 |divorced|10    |\n",
      "|32 |married |87    |\n",
      "|32 |single  |124   |\n",
      "|31 |divorced|15    |\n",
      "|31 |married |80    |\n",
      "|31 |single  |111   |\n",
      "|30 |married |59    |\n",
      "|30 |divorced|7     |\n",
      "|30 |single  |151   |\n",
      "|29 |married |33    |\n",
      "|29 |single  |133   |\n",
      "|29 |divorced|5     |\n",
      "|28 |divorced|4     |\n",
      "|28 |married |20    |\n",
      "|28 |single  |138   |\n",
      "|27 |married |29    |\n",
      "|27 |single  |110   |\n",
      "|27 |divorced|2     |\n",
      "|26 |single  |121   |\n",
      "|26 |married |13    |\n",
      "|25 |married |14    |\n",
      "|25 |single  |99    |\n",
      "|24 |married |10    |\n",
      "|24 |single  |58    |\n",
      "|23 |single  |42    |\n",
      "|23 |married |2     |\n",
      "|22 |single  |40    |\n",
      "|21 |married |1     |\n",
      "|21 |single  |21    |\n",
      "|20 |single  |14    |\n",
      "|20 |married |1     |\n",
      "|19 |single  |11    |\n",
      "|18 |single  |7     |\n",
      "+---+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT age, marital, count(*) as number from bank\\\n",
    "            where y = 'yes' group by age, marital order by age desc\").show(data.count(),False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostly as u can see that in married and single people in the \n",
    "\n",
    "age group of 25 - 40 gone for subscription\n",
    "\n",
    "So related"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|age|\n",
      "+---+\n",
      "| 58|\n",
      "| 44|\n",
      "| 33|\n",
      "| 47|\n",
      "| 33|\n",
      "+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(\"age\").show(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# data.select('age').rdd.map(lambda x: ageStr(x)).show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# \"\"\"Converting function to UDF\"\"\"\n",
    "# convertUDF = udf(lambda x: ageStr(z),StringType())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# data.select(col(\"age\"), \\\n",
    "#     convertUDF(col(\"age\")).alias(\"Age_\") ) \\\n",
    "#    .show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# data.withColumn(\"age_\",ageStr(col(\"age\"))).show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# data.withColumn(\"age_\",convertUDF(col(\"age\"))).show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# spark.udf.register(\"convertUDF\",ageStr,StringType())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# spark.sql(\"SELECT convertUDF(age) as age, count(*) as number from bank\\\n",
    "#         where y = 'yes' group by age\").show(data.count(),False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# data.withColumn(\n",
    "#   \"age_\", \n",
    "#   when((col(\"age\") >= 60) & (col(\"age\")<=100),lit(\"Old\").otherwise(\n",
    "#     when((col(\"age\") >= 40) & (col(\"age\")<60),lit(\"Middle Age\").otherwise(\n",
    "#         when((col(\"age\") >= 20) & (col(\"age\")<40),lit(\"Young\").otherwise(lit(\"Teen\")))))\n",
    "#   ))\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: integer (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------+\n",
      "| col_name|data_type|comment|\n",
      "+---------+---------+-------+\n",
      "|      age|      int|   null|\n",
      "|      job|   string|   null|\n",
      "|  marital|   string|   null|\n",
      "|education|   string|   null|\n",
      "|  default|   string|   null|\n",
      "|  balance|      int|   null|\n",
      "|  housing|   string|   null|\n",
      "|     loan|   string|   null|\n",
      "|  contact|   string|   null|\n",
      "|      day|      int|   null|\n",
      "|    month|   string|   null|\n",
      "| duration|      int|   null|\n",
      "| campaign|      int|   null|\n",
      "|    pdays|      int|   null|\n",
      "| previous|      int|   null|\n",
      "| poutcome|   string|   null|\n",
      "|        y|   string|   null|\n",
      "+---------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"desc bank\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ageStr(a):\n",
    "    if (a >= 60):\n",
    "        return \"Old\"\n",
    "    elif ((a >= 40) & (a < 60)):\n",
    "        return \"Middle Age\"\n",
    "    elif ((a >= 20) & (a < 40)):\n",
    "        return \"Young\"\n",
    "    elif ((a >= 13) & (a < 20)):\n",
    "        return \"Teen\"\n",
    "    else:\n",
    "        return \"Kid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf,col,when,lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_ageStr = udf(ageStr,StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "datau = data.withColumn(\"ageStrings\",udf_ageStr(\"age\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+--------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+----------+\n",
      "|age|         job| marital|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|  y|ageStrings|\n",
      "+---+------------+--------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+----------+\n",
      "| 58|  management| married| tertiary|     no|   2143|    yes|  no|unknown|  5|  may|     261|       1|   -1|       0| unknown| no|Middle Age|\n",
      "| 44|  technician|  single|secondary|     no|     29|    yes|  no|unknown|  5|  may|     151|       1|   -1|       0| unknown| no|Middle Age|\n",
      "| 33|entrepreneur| married|secondary|     no|      2|    yes| yes|unknown|  5|  may|      76|       1|   -1|       0| unknown| no|     Young|\n",
      "| 47| blue-collar| married|  unknown|     no|   1506|    yes|  no|unknown|  5|  may|      92|       1|   -1|       0| unknown| no|Middle Age|\n",
      "| 33|     unknown|  single|  unknown|     no|      1|     no|  no|unknown|  5|  may|     198|       1|   -1|       0| unknown| no|     Young|\n",
      "| 35|  management| married| tertiary|     no|    231|    yes|  no|unknown|  5|  may|     139|       1|   -1|       0| unknown| no|     Young|\n",
      "| 28|  management|  single| tertiary|     no|    447|    yes| yes|unknown|  5|  may|     217|       1|   -1|       0| unknown| no|     Young|\n",
      "| 42|entrepreneur|divorced| tertiary|    yes|      2|    yes|  no|unknown|  5|  may|     380|       1|   -1|       0| unknown| no|Middle Age|\n",
      "| 58|     retired| married|  primary|     no|    121|    yes|  no|unknown|  5|  may|      50|       1|   -1|       0| unknown| no|Middle Age|\n",
      "| 43|  technician|  single|secondary|     no|    593|    yes|  no|unknown|  5|  may|      55|       1|   -1|       0| unknown| no|Middle Age|\n",
      "| 41|      admin.|divorced|secondary|     no|    270|    yes|  no|unknown|  5|  may|     222|       1|   -1|       0| unknown| no|Middle Age|\n",
      "| 29|      admin.|  single|secondary|     no|    390|    yes|  no|unknown|  5|  may|     137|       1|   -1|       0| unknown| no|     Young|\n",
      "| 53|  technician| married|secondary|     no|      6|    yes|  no|unknown|  5|  may|     517|       1|   -1|       0| unknown| no|Middle Age|\n",
      "| 58|  technician| married|  unknown|     no|     71|    yes|  no|unknown|  5|  may|      71|       1|   -1|       0| unknown| no|Middle Age|\n",
      "| 57|    services| married|secondary|     no|    162|    yes|  no|unknown|  5|  may|     174|       1|   -1|       0| unknown| no|Middle Age|\n",
      "| 51|     retired| married|  primary|     no|    229|    yes|  no|unknown|  5|  may|     353|       1|   -1|       0| unknown| no|Middle Age|\n",
      "| 45|      admin.|  single|  unknown|     no|     13|    yes|  no|unknown|  5|  may|      98|       1|   -1|       0| unknown| no|Middle Age|\n",
      "| 57| blue-collar| married|  primary|     no|     52|    yes|  no|unknown|  5|  may|      38|       1|   -1|       0| unknown| no|Middle Age|\n",
      "| 60|     retired| married|  primary|     no|     60|    yes|  no|unknown|  5|  may|     219|       1|   -1|       0| unknown| no|       Old|\n",
      "| 33|    services| married|secondary|     no|      0|    yes|  no|unknown|  5|  may|      54|       1|   -1|       0| unknown| no|     Young|\n",
      "+---+------------+--------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datau.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "datau.createOrReplaceTempView(\"bank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+------+\n",
      "|ageStrings|marital |number|\n",
      "+----------+--------+------+\n",
      "|Middle Age|married |1250  |\n",
      "|Middle Age|divorced|335   |\n",
      "|Middle Age|single  |263   |\n",
      "|Old       |divorced|118   |\n",
      "|Old       |married |469   |\n",
      "|Old       |single  |13    |\n",
      "|Teen      |single  |18    |\n",
      "|Young     |divorced|169   |\n",
      "|Young     |single  |1618  |\n",
      "|Young     |married |1036  |\n",
      "+----------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT ageStrings, marital, count(*) as number from bank\\\n",
    "            where y = 'yes' group by ageStrings, marital order by ageStrings\").show(data.count(),False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that \n",
    "\n",
    "people of age group young with marital status single and \n",
    "\n",
    "middle aged people with marital status married\n",
    "\n",
    "are mostly going for the subscription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---+------+\n",
      "|ageStrings|marital |y  |number|\n",
      "+----------+--------+---+------+\n",
      "|Middle Age|divorced|yes|335   |\n",
      "|Middle Age|divorced|no |2968  |\n",
      "|Middle Age|married |yes|1250  |\n",
      "|Middle Age|married |no |13298 |\n",
      "|Middle Age|single  |yes|263   |\n",
      "|Middle Age|single  |no |1951  |\n",
      "|Old       |divorced|yes|118   |\n",
      "|Old       |divorced|no |185   |\n",
      "|Old       |married |no |951   |\n",
      "|Old       |married |yes|469   |\n",
      "|Old       |single  |yes|13    |\n",
      "|Old       |single  |no |48    |\n",
      "|Teen      |single  |no |29    |\n",
      "|Teen      |single  |yes|18    |\n",
      "|Young     |divorced|no |1432  |\n",
      "|Young     |divorced|yes|169   |\n",
      "|Young     |married |no |10210 |\n",
      "|Young     |married |yes|1036  |\n",
      "|Young     |single  |no |8850  |\n",
      "|Young     |single  |yes|1618  |\n",
      "+----------+--------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT ageStrings, marital,y, count(y) as number from bank\\\n",
    "            group by ageStrings, marital, y order by ageStrings, marital\").show(data.count(),False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can view a more detailed analysis of the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
